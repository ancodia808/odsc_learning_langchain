{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269a9b6b-e8b6-49da-aeda-b2b3e38bbf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original documents: 1\n",
      "Number of split chunks: 4920\n",
      "\n",
      "split_docs[0].page_content: In Metal Gear Solid V: The Phantom Pain, the player can access cassette tapes, either at hand or by\n",
      "\n",
      "split_docs[0].metadata: {'source': 'txt/mgs5_cassette_tapes.txt'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load Documents\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "## Load Text\n",
    "loader = TextLoader(\"txt/mgs5_cassette_tapes.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "## Split Text\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "# chunk_size: The maximum size of each chunk (in characters by default).\n",
    "# chunk_overlap: The number of characters to overlap between consecutive chunks,\n",
    "#                helping to maintain context.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,  # Use character length for chunk size\n",
    "    is_separator_regex=False, # Treat separators literally\n",
    ")\n",
    "\n",
    "# Split the loaded documents\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the resulting chunks\n",
    "print(f\"Number of original documents: {len(documents)}\")\n",
    "print(f\"Number of split chunks: {len(split_docs)}\\n\")\n",
    "\n",
    "#for i, chunk in enumerate(split_docs):\n",
    "#    print(f\"Chunk {i+1}:\\n{chunk.page_content}\\n---\")\n",
    "print(f\"split_docs[0].page_content: {split_docs[0].page_content}\\n\")\n",
    "print(f\"split_docs[0].metadata: {split_docs[0].metadata}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8f3a92-18ed-49c8-b937-483cbc5aa7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OCI embeddings and generative AI.\n"
     ]
    }
   ],
   "source": [
    "### Connect to OCI embeddings and generative AI\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatOCIGenAI\n",
    "\n",
    "oci_embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-english-light-v3.0\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    ")\n",
    "\n",
    "oci_chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-a-03-2025\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "print(\"Connected to OCI embeddings and generative AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fbfdb51-7913-40e6-9f86-e595acf00a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embed Documents\n",
    "#l = len(split_docs)\n",
    "#embeddings = []\n",
    "#for i in range(l // 16 + 1):\n",
    "#    #print(f\"Embedding from index {i*16} to {(i + 1) * 16}...\")\n",
    "#    subdocs = [item.page_content for item in split_docs[i * 16: (i + 1) * 16]]\n",
    "#    embeddings.extend(oci_embeddings.embed_documents(subdocs))\n",
    "#\n",
    "#print(\"Documents embedded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84050aa-5d67-449d-98d7-1ce0b3e0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build Vector Store (FAISS)\n",
    "#from langchain_community.vectorstores import FAISS\n",
    "#\n",
    "#texts = [item.page_content for item in split_docs]\n",
    "#text_embedding_pairs = [(text, embed) for text, embed in zip(texts, embeddings)]\n",
    "#vectorstore = FAISS.from_embeddings(text_embedding_pairs, oci_embeddings)\n",
    "#\n",
    "#print(\"FAISS vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f0671a-eda9-4b1a-ab6c-8ff7c6cbc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.vectorstores import Chroma\n",
    "#from langchain_core.documents import Document\n",
    "#\n",
    "## 2. Define some documents to add to the vector store\n",
    "#documents = [\n",
    "#    Document(page_content=\"The quick brown fox jumps over the lazy dog.\", metadata={\"source\": \"fable\"}),\n",
    "#    Document(page_content=\"Artificial intelligence is transforming industries worldwide.\", metadata={\"source\": \"technology\"}),\n",
    "#    Document(page_content=\"The capital of France is Paris.\", metadata={\"source\": \"geography\"}),\n",
    "#]\n",
    "#\n",
    "## 3. Create a Chroma vector store instance\n",
    "## You can specify a persist_directory to save the data to disk\n",
    "#persist_directory = \"./chroma_db\"\n",
    "#vectorstore = Chroma.from_documents(\n",
    "#    documents=documents,\n",
    "#    embedding=embeddings,\n",
    "#    persist_directory=persist_directory,\n",
    "#    collection_name=\"my_documents\"\n",
    "#)\n",
    "#print(\"Chroma vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80071137-6575-4d4d-8818-a7a8b7110f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Build Vector Store (In-Memory)\n",
    "#from langchain_core.vectorstores import InMemoryVectorStore\n",
    "#\n",
    "## Create an in-memory vector store\n",
    "#vectorstore = InMemoryVectorStore(oci_embeddings)\n",
    "#vectorstore.add_documents(documents=split_docs)\n",
    "#\n",
    "#print(\"In-memory vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0928b9-3f8a-450f-ba37-66dad3d3c00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store built.\n"
     ]
    }
   ],
   "source": [
    "### Build Vector Store (FAISS)\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_docs, oci_embeddings)\n",
    "\n",
    "print(\"FAISS vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a178f33e-b6dd-43b6-ada9-0e9865319f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain built.\n"
     ]
    }
   ],
   "source": [
    "### Build Chain (OCI chat-based Retrieval QA)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "#from langchain_classic.chains import RetrievalQA\n",
    "#from langchain_community.chains import RetrievalQA\n",
    "#from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever(retriever_kwargs={\"similarity_top_k\": 3})\n",
    "\n",
    "#rag_prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "#rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.  You don't have to mention whether you did or did not use the context.\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=oci_chat,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt,},\n",
    ")\n",
    "\n",
    "#rag = RetrievalQA.from_chain_type(\n",
    "#    llm=oci_chat,\n",
    "#    chain_type=\"stuff\",\n",
    "#    retriever=retriever,\n",
    "#    return_source_documents=True,\n",
    "#    verbose=False,\n",
    "#)\n",
    "\n",
    "print(\"RAG chain built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80248d8e-4949-4be4-8490-a9f5d1ef30b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Who is Kazuhira?', 'result': 'Based on the provided context, Kazuhira appears to be Benedict \"Kazuhira\" Miller, a figure associated with research and an epiphany related to \"The Hamburgers of Kazuhira Miller.\" However, the context does not provide further details about who Kazuhira is beyond this association. \\n\\nSince the context is limited, I will use my general knowledge: Kazuhira Miller is a character from the *Metal Gear* video game series, specifically *Metal Gear Solid V: The Phantom Pain*. He is a mentor figure to the protagonist, Venom Snake, and plays a significant role in the game\\'s story.'}\n",
      "{'query': 'Are Venom Snake and Revolver Ocelot friends?', 'result': \"Based on the provided context, it's not explicitly stated whether Venom Snake and Revolver Ocelot are friends. Their dialogue suggests a level of familiarity and a working relationship, but the tone is more professional and tactical rather than friendly. Ocelot's preference to work alone and the strategic nature of their conversation imply a collaborative but not necessarily friendly dynamic. Without additional context, itâ€™s unclear if their relationship extends beyond professional cooperation. \\n\\nUsing general knowledge, in the *Metal Gear* series, Venom Snake and Revolver Ocelot have a complex relationship shaped by their roles in the story. While they often work together, their interactions are typically driven by mission objectives rather than personal friendship. Ocelot, in particular, is known for his manipulative and enigmatic nature, which further complicates any straightforward interpretation of their relationship.\"}\n",
      "{'query': \"What is the name of Anderson's AI?\", 'result': 'Based on the provided context, the name of Anderson\\'s AI project is **\"The Patriots.\"** However, the context does not specify the name of the AI itself, only the project name. If we rely solely on the given information, there is no direct answer to the name of the AI. If we were to use general knowledge or additional context, it would not be applicable here. Therefore, the answer remains that the project is called \"The Patriots,\" but the AI\\'s specific name is not provided.'}\n",
      "{'query': \"What is Zero's fear once the Cold War is over?\", 'result': \"Based on the provided context, Zero's fear once the Cold War is over is that the enemies won't be so clearly defined.\"}\n",
      "{'query': 'How many cassette tapes are there in Metal Gear Solid 5?', 'result': 'Based on the provided context, there are **151 cassette tapes** in Metal Gear Solid V.'}\n"
     ]
    }
   ],
   "source": [
    "### Invoke the chain (unit test)\n",
    "print(rag.invoke(\"Who is Kazuhira?\"))\n",
    "print(rag.invoke(\"Are Venom Snake and Revolver Ocelot friends?\"))\n",
    "print(rag.invoke(\"What is the name of Anderson's AI?\"))\n",
    "print(rag.invoke(\"What is Zero's fear once the Cold War is over?\"))\n",
    "print(rag.invoke(\"How many cassette tapes are there in Metal Gear Solid 5?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cab1a17-b164-4bb3-b166-0d207af9a8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Available</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Available     Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Not Available Local tested .predict from score.py                               \n",
       "save()    Not Available Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use ADS to deploy the unit-tested chain\n",
    "## Create the ADS deployment object\n",
    "import tempfile\n",
    "from ads.llm.deploy import ChainDeployment\n",
    "\n",
    "artifact_dir = tempfile.mkdtemp()\n",
    "\n",
    "ads_deployment = ChainDeployment(\n",
    "    chain=rag,\n",
    "    artifact_dir=artifact_dir,\n",
    "    force_overwrite=True\n",
    ")\n",
    "\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce986b5a-f2ce-4e00-9100-78e4f52fd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/model/runtime/env_info.py:92: UserWarning: slug will be deprecated. Provide conda pack path instead.s]\n",
      "  warnings.warn(\"slug will be deprecated. Provide conda pack path instead.\")\n",
      "\n",
      "INFO:ADS:To auto-extract taxonomy metadata the model must be provided. Supported models: keras, lightgbm, pytorch, sklearn, tensorflow, pyspark, and xgboost.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Needs Action</th>\n",
       "      <th>Serialized model</th>\n",
       "      <td>Model is not automatically serialized. Serialize the model as `model.pkl` and save to the /tmp/tmpl4qnq2nz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Done</th>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                          Actions Needed\n",
       "Step      Status        Details                                                                                                                                                         \n",
       "initiate  Done          Initiated the model                                                                                                                                             \n",
       "prepare() Done          Generated runtime.yaml                                                                                                                                          \n",
       "                        Generated score.py                                                                                                                                              \n",
       "          Needs Action  Serialized model                                     Model is not automatically serialized. Serialize the model as `model.pkl` and save to the /tmp/tmpl4qnq2nz.\n",
       "          Done          Populated metadata(Custom, Taxonomy and Provenance)                                                                                                             \n",
       "verify()  Available     Local tested .predict from score.py                                                                                                                             \n",
       "save()    Available     Conducted Introspect Test                                                                                                                                       \n",
       "                        Uploaded artifact to model catalog                                                                                                                              \n",
       "deploy()  UNKNOWN       Deployed the model                                                                                                                                              \n",
       "predict() Not Available Called deployment predict endpoint                                                                                                                              "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the ADS deployment\n",
    "ads_deployment.prepare(\n",
    "    inference_conda_env=\"automlx251_p311_cpu_x86_64_v2\",\n",
    "    inference_python_version=\"3.11\",\n",
    "    force_overwrite=True,\n",
    ")\n",
    "\n",
    "# Summarize the checkpoitn ADS workflow status\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e1e3108-8e2f-4367-8e17-37585bc1955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8128/267121191.py\", line 2, in <module>\n",
      "    ads_deployment.verify(\"Who wants to cook hamburgers once the conflict is over?\")\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/model/generic_model.py\", line 1291, in verify\n",
      "    self.model_artifact.reload()\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/model/artifact.py\", line 441, in reload\n",
      "    spec.loader.exec_module(self.score)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/tmp/tmpl4qnq2nz/score.py\", line 96, in <module>\n",
      "    def predict(data, model=load_model(), input_schema_path=os.path.join(os.path.dirname(os.path.realpath(__file__)), \"input_schema.json\")):\n",
      "                            ^^^^^^^^^^^^\n",
      "  File \"/tmp/tmpl4qnq2nz/score.py\", line 36, in load_model\n",
      "    return ChainDeployment.load_chain(chain_yaml_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/llm/deploy.py\", line 63, in load_chain\n",
      "    return load_from_yaml(yaml_uri, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/llm/serialize.py\", line 144, in load_from_yaml\n",
      "    return load(\n",
      "           ^^^^^\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/llm/serialize.py\", line 112, in load\n",
      "    return custom_deserialization[obj_type](obj, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/datascience/conda/automlx251_p311_cpu_x86_64_v2/lib/python3.11/site-packages/ads/llm/serializers/retrieval_qa.py\", line 121, in load\n",
      "    retriever_kwargs = config_param.pop(\"retriever_kwargs\")\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyError: 'retriever_kwargs'\n",
      "KeyError: 'retriever_kwargs'"
     ]
    }
   ],
   "source": [
    "# Save the ADS model\n",
    "ads_deployment.verify(\"Who wants to cook hamburgers once the conflict is over?\")\n",
    "\n",
    "# Summarize the checkpoitn ADS workflow status\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae250db-ccca-4999-b1ea-3cf3271be72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ADS model\n",
    "model_id = ads_deployment.save()\n",
    "\n",
    "# Summarize the checkpoitn ADS workflow status\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9051f689-68c2-4e8a-b481-d3ccae737f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:automlx251_p311_cpu_x86_64_v2]",
   "language": "python",
   "name": "conda-env-automlx251_p311_cpu_x86_64_v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
