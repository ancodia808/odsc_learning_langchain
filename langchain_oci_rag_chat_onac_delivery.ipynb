{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269a9b6b-e8b6-49da-aeda-b2b3e38bbf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/home/datascience/demo/pptx/nacie_integration_performance_discussion_20250814.pptx'}\n",
      "Number of original documents: 1\n",
      "Number of split chunks: 208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "### Load Documents\n",
    "## PowerPoint Presentations\n",
    "# Replace with the actual path to your PowerPoint file\n",
    "file_path = \"/home/datascience/demo/pptx/nacie_integration_performance_discussion_20250814.pptx\" \n",
    "\n",
    "# Create an instance of the loader\n",
    "loader = UnstructuredPowerPointLoader(file_path)\n",
    "\n",
    "# Load the data from the file\n",
    "documents = loader.load()\n",
    "\n",
    "# The 'data' variable now holds a list of LangChain Document objects\n",
    "# You can inspect the content and metadata of the documents:\n",
    "#print(documents[0].page_content)\n",
    "print(documents[0].metadata)\n",
    "\n",
    "## Split Text\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "# chunk_size: The maximum size of each chunk (in characters by default).\n",
    "# chunk_overlap: The number of characters to overlap between consecutive chunks,\n",
    "#                helping to maintain context.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,  # Use character length for chunk size\n",
    "    is_separator_regex=False, # Treat separators literally\n",
    ")\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(\n",
    "#    chunk_size=1000,\n",
    "#    chunk_overlap=50,\n",
    "#    length_function=len,  # Use character length for chunk size\n",
    "#    is_separator_regex=False, # Treat separators literally\n",
    "#)\n",
    "\n",
    "# Split the loaded documents\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the resulting chunks\n",
    "print(f\"Number of original documents: {len(documents)}\")\n",
    "print(f\"Number of split chunks: {len(split_docs)}\\n\")\n",
    "\n",
    "#for i, chunk in enumerate(split_docs):\n",
    "#    print(f\"Chunk {i+1}:\\n{chunk.page_content}\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8f3a92-18ed-49c8-b937-483cbc5aa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embed Documents\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "oci_embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-english-light-v3.0\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    ")\n",
    "\n",
    "l = len(split_docs)\n",
    "embeddings = []\n",
    "for i in range(l // 16 + 1):\n",
    "    #print(f\"Embedding from index {i*16} to {(i + 1) * 16}...\")\n",
    "    subdocs = [item.page_content for item in split_docs[i * 16: (i + 1) * 16]]\n",
    "    embeddings.extend(oci_embeddings.embed_documents(subdocs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84050aa-5d67-449d-98d7-1ce0b3e0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Vector Store (FAISS)\n",
    "#vectorstore = FAISS.from_texts(\n",
    "#    [\n",
    "#        \"Larry Ellison co-founded Oracle Corporation in 1977 with Bob Miner and Ed Oates.\",\n",
    "#        \"Oracle Corporation is an American multinational computer technology company headquartered in Austin, Texas, United States.\",\n",
    "#    ],\n",
    "#    embedding=embeddings,\n",
    "#)\n",
    "\n",
    "texts = [item.page_content for item in split_docs]\n",
    "text_embedding_pairs = [(text, embed) for text, embed in zip(texts, embeddings)]\n",
    "vectorstore = FAISS.from_embeddings(text_embedding_pairs, oci_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a178f33e-b6dd-43b6-ada9-0e9865319f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What are the 4 pillars of performance?', 'result': 'The 4 pillars of performance, as outlined in the context, are:\\n\\n1. **Growth**  \\n2. **Productivity**  \\n3. **Health**  \\n4. **Innovation**'}\n",
      "{'query': 'Why is Productivity important?', 'result': \"Based on the provided context, Productivity is important because it **measures individual contribution to revenue**. This suggests that tracking productivity helps assess how much each person is directly impacting the company's financial performance.\"}\n",
      "{'query': 'Can I ignore any of the 4 pillars of performance?', 'result': 'Based on the provided context, the 4 pillars of performance are:\\n\\n1. **Growth**\\n2. **Productivity**\\n3. **Health**\\n4. **Innovation**\\n\\nThe context emphasizes the \"Evolving 4-Pillar Approach,\" suggesting that these pillars are interconnected and essential for overall performance. There is no indication that any pillar can be ignored. In fact, the repetition of the pillars implies their equal importance.\\n\\nTherefore, **no**, you should not ignore any of the 4 pillars of performance, as they collectively contribute to a comprehensive and balanced approach to achieving optimal performance.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOCIGenAI\n",
    "\n",
    "### Build Chain (OCI chat-based Retrieval QA)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#rag_prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "#rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.  You don't have to mention whether you did or did not use the context.\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "oci_chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-a-03-2025\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=oci_chat,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": rag_prompt,},\n",
    ")\n",
    "\n",
    "print(rag.invoke(\"What are the 4 pillars of performance?\"))\n",
    "print(rag.invoke(\"Why is Productivity important?\"))\n",
    "print(rag.invoke(\"Can I ignore any of the 4 pillars of performance?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be5fa0-0d0d-4e5a-b9ff-fe12c34bfc01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_p312_any_x86_64_v1]",
   "language": "python",
   "name": "conda-env-python_p312_any_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
