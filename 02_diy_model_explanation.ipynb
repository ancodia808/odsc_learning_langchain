{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d8e0b3-34ce-420b-ac55-eb80647057b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import automlx\n",
    "import pandas as pd\n",
    "\n",
    "from automlx import init\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the standard, publicly-available iris data set\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = pd.Series(data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e8f3898-81f9-4c84-99a0-3f931265476f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "..                 ...               ...                ...               ...\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f96f4f-70dc-4f8e-8132-20c24a0a5b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The target in the iris dataset represents the species of iris\n",
    "# 0: Iris setosa\n",
    "# 1: Iris versicolor\n",
    "# 2: Iris virginica \n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f15951-1633-4012-9264-f68dd96bbe81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 4), (45, 4))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into appropriate training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,\n",
    "                                                        y,\n",
    "                                                        train_size=0.7,\n",
    "                                                        random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2808b13-317f-46ed-8c3f-dc219a4c1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set and initialize the AutoMLx engine\n",
    "init(engine='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41208378-426a-449f-b410-add5cee3ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-30 19:32:13,333] [automlx.interface] Dataset shape: (105,4)\n",
      "[2025-11-30 19:32:13,472] [automlx.data_transform] Running preprocessing. Number of features: 5\n",
      "[2025-11-30 19:32:13,970] [automlx.data_transform] Preprocessing completed. Took 0.497 secs\n",
      "[2025-11-30 19:32:13,987] [automlx.process] Running Model Generation\n",
      "[2025-11-30 19:32:14,165] [automlx.process] Model Generation completed.\n",
      "[2025-11-30 19:32:14,334] [automlx.model_selection] Running Model Selection\n",
      "[2025-11-30 19:33:17,907] [automlx.model_selection] Model Selection completed - Took 63.573 sec - Selected models: [['ExtraTreesClassifier']]\n",
      "[2025-11-30 19:33:17,968] [automlx.adaptive_sampling] Running Adaptive Sampling. Dataset shape: (105,5).\n",
      "[2025-11-30 19:33:18,015] [automlx.adaptive_sampling] Adaptive Sampling: top_limit: 32 < bottom_limit: 1000,\n",
      "sampling process will be skipped\n",
      "[2025-11-30 19:33:18,019] [automlx.adaptive_sampling] Adaptive Sampling: top_limit: 8 < bottom_limit: 1000,\n",
      "sampling process will be skipped\n",
      "[2025-11-30 19:33:18,232] [automlx.feature_selection] Starting feature ranking for ExtraTreesClassifier\n",
      "[2025-11-30 19:33:26,580] [automlx.feature_selection] Feature Selection completed. Took 8.376 secs.\n",
      "[2025-11-30 19:33:26,636] [automlx.trials] Running Model Tuning for ['ExtraTreesClassifier']\n"
     ]
    }
   ],
   "source": [
    "# Train a model using AutoMLx\n",
    "# Exclude LightGBM because it creates so many warnings on such a small data set.\n",
    "# For reference here is the complete list of model's for classification\n",
    "#model_list = [\n",
    "#    \"CatBoostClassifier\", \n",
    "#    \"DecisionTreeClassifier\", \n",
    "#    \"ExtraTreesClassifier\", \n",
    "#    \"GaussianNB\", \n",
    "#    \"KNeighborsClassifier\", \n",
    "#    \"LGBMClassifier\", \n",
    "#    \"LogisticRegression\", \n",
    "#    \"RandomForestClassifier\", \n",
    "#    \"SVC\", \n",
    "#    \"TorchMLPClassifier\", \n",
    "#    \"XGBClassifier\"\n",
    "#]\n",
    "\n",
    "model_list = [\n",
    "    \"CatBoostClassifier\", \n",
    "    \"DecisionTreeClassifier\", \n",
    "    \"ExtraTreesClassifier\", \n",
    "    \"GaussianNB\", \n",
    "    \"KNeighborsClassifier\", \n",
    "    \"LogisticRegression\", # <-- Notice that \"LGBMClassifier\" has been dropped from the list here..\n",
    "    \"RandomForestClassifier\", \n",
    "    \"SVC\", \n",
    "    \"TorchMLPClassifier\", \n",
    "    \"XGBClassifier\"\n",
    "]\n",
    "\n",
    "est = automlx.Pipeline(model_list=model_list, task='classification')\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce8133-5b4b-4a9c-9d48-19f7614e4fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the F1_score scoreing metric to evaluate the model's performance\n",
    "y_pred = est.predict(X_test)\n",
    "score_default = f1_score(y_test, y_pred, average='macro')\n",
    "print(f'Score on test data : {score_default}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af9c38-e062-4b04-8198-7479274b69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the generated classifier\n",
    "explainer = automlx.MLExplainer(est,\n",
    "                                   X_train,\n",
    "                                   y_train,\n",
    "                                   task=\"classification\")\n",
    "\n",
    "result_explain_model_default = explainer.explain_model()\n",
    "result_explain_model_default.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06393607-9802-48be-b5f6-90cdb48bf391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the local explanation for a single dataset row\n",
    "print(\"Explain the first row in our test data set...\")\n",
    "result_explain_prediction = explainer.explain_prediction(X=X_test.loc[X_test.index[0]])\n",
    "print(result_explain_prediction)\n",
    "      \n",
    "print(\"Explain the second row in our test data set...\")\n",
    "result_explain_prediction = explainer.explain_prediction(X=X_test.loc[X_test.index[1]])\n",
    "print(result_explain_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9fe6c-d9fe-4739-9610-1fd290ca31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the what if explaination for our test data set\n",
    "result_explore_whatif = explainer.explore_whatif(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bce4ea-b24f-4c48-955c-2a2dbb29db61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:onac_diy_v2_0]",
   "language": "python",
   "name": "conda-env-onac_diy_v2_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
