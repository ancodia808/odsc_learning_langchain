{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a9b6b-e8b6-49da-aeda-b2b3e38bbf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from ads.llm.deploy import ChainDeployment\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models import ChatOCIGenAI\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "ads.set_auth(auth=\"resource_principal\")\n",
    "\n",
    "### Load Documents\n",
    "file_extension = \".pptx\"\n",
    "directory_path = \"/home/datascience/demo/pptx\"\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if filename.endswith(file_extension) and os.path.isfile(file_path):\n",
    "        loader = UnstructuredPowerPointLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "# The 'data' variable now holds a list of LangChain Document objects\n",
    "# You can inspect the content and metadata of the documents:\n",
    "#print(documents[0].page_content)\n",
    "#print(documents[0].metadata)\n",
    "\n",
    "## Split Text\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "# chunk_size: The maximum size of each chunk (in characters by default).\n",
    "# chunk_overlap: The number of characters to overlap between consecutive chunks,\n",
    "#                helping to maintain context.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,  # Use character length for chunk size\n",
    "    is_separator_regex=False, # Treat separators literally\n",
    ")\n",
    "\n",
    "# Split the loaded documents\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the resulting chunks\n",
    "print(f\"Number of original documents: {len(documents)}\")\n",
    "print(f\"Number of split chunks: {len(split_docs)}\\n\")\n",
    "\n",
    "#for i, chunk in enumerate(split_docs):\n",
    "#    print(f\"Chunk {i+1}:\\n{chunk.page_content}\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f3a92-18ed-49c8-b937-483cbc5aa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Connect to OCI embeddings and generative AI\n",
    "\n",
    "oci_embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-english-light-v3.0\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    ")\n",
    "\n",
    "oci_chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-a-03-2025\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "print(\"Connected to OCI embeddings and generative AI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84050aa-5d67-449d-98d7-1ce0b3e0efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Vector Store (FAISS)\n",
    "vectorstore = FAISS.from_documents(split_docs, oci_embeddings)\n",
    "\n",
    "print(\"FAISS vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178f33e-b6dd-43b6-ada9-0e9865319f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build Chain (OCI chat-based Retrieval QA)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#rag_prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "#rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.  You don't have to mention whether you did or did not use the context.\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "\n",
    "#rag = RetrievalQA.from_chain_type(\n",
    "#    llm=oci_chat,\n",
    "#    retriever=retriever,\n",
    "#    chain_type_kwargs={\"prompt\": rag_prompt,},\n",
    "#)\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=oci_chat,\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "print(\"RAG chain built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be5fa0-0d0d-4e5a-b9ff-fe12c34bfc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Invoke the chain (unit test)\n",
    "print(rag.invoke(\"What are the 4 pillars of performance?\"))\n",
    "print(rag.invoke(\"Why is Productivity important?\"))\n",
    "print(rag.invoke(\"Can I ignore any of the 4 pillars of performance?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adc8c1e-a5df-4d07-b6a2-f8cdf3dd42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use ADS to deploy the unit-tested chain\n",
    "### Create the ADS deployment object\n",
    "#artifact_dir = tempfile.mkdtemp()\n",
    "#\n",
    "#ads_deployment = ChainDeployment(\n",
    "#    chain=rag,\n",
    "#    artifact_dir=artifact_dir,\n",
    "#    force_overwrite=True\n",
    "#)\n",
    "#\n",
    "#ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2d73e-63bf-42d1-bc0b-22ce9e3acba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the ADS deployment\n",
    "#ads_deployment.prepare(\n",
    "#    inference_conda_env=\"python_p312_any_x86_64_v1\",\n",
    "#    inference_python_version=\"3.12\",\n",
    "#)\n",
    "#\n",
    "## Summarize the checkpoitn ADS workflow status\n",
    "#ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3ee04-cb74-4540-8276-8f260e9b1c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:onac_diy_v2_0]",
   "language": "python",
   "name": "conda-env-onac_diy_v2_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
