{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269a9b6b-e8b6-49da-aeda-b2b3e38bbf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/home/datascience/demo/pptx/nacie_integration_team_meeting_20251009.pptx'}\n",
      "Number of original documents: 3\n",
      "Number of split chunks: 588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Load Documents\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "import os\n",
    "\n",
    "file_extension = \".pptx\"\n",
    "directory_path = \"/home/datascience/demo/pptx\"\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if filename.endswith(file_extension) and os.path.isfile(file_path):\n",
    "        loader = UnstructuredPowerPointLoader(file_path)\n",
    "        documents.extend(loader.load())\n",
    "\n",
    "# The 'data' variable now holds a list of LangChain Document objects\n",
    "# You can inspect the content and metadata of the documents:\n",
    "#print(documents[0].page_content)\n",
    "#print(documents[0].metadata)\n",
    "\n",
    "## Split Text\n",
    "# Initialize the RecursiveCharacterTextSplitter\n",
    "# chunk_size: The maximum size of each chunk (in characters by default).\n",
    "# chunk_overlap: The number of characters to overlap between consecutive chunks,\n",
    "#                helping to maintain context.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,  # Use character length for chunk size\n",
    "    is_separator_regex=False, # Treat separators literally\n",
    ")\n",
    "\n",
    "# Split the loaded documents\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Print the resulting chunks\n",
    "print(f\"Number of original documents: {len(documents)}\")\n",
    "print(f\"Number of split chunks: {len(split_docs)}\\n\")\n",
    "\n",
    "#for i, chunk in enumerate(split_docs):\n",
    "#    print(f\"Chunk {i+1}:\\n{chunk.page_content}\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8f3a92-18ed-49c8-b937-483cbc5aa7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to OCI embeddings and generative AI.\n"
     ]
    }
   ],
   "source": [
    "### Connect to OCI embeddings and generative AI\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.chat_models import ChatOCIGenAI\n",
    "\n",
    "oci_embeddings = OCIGenAIEmbeddings(\n",
    "    model_id=\"cohere.embed-english-light-v3.0\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    ")\n",
    "\n",
    "oci_chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-a-03-2025\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    ")\n",
    "\n",
    "print(\"Connected to OCI embeddings and generative AI.\")\n",
    "\n",
    "#l = len(split_docs)\n",
    "#embeddings = []\n",
    "#for i in range(l // 16 + 1):\n",
    "#    #print(f\"Embedding from index {i*16} to {(i + 1) * 16}...\")\n",
    "#    subdocs = [item.page_content for item in split_docs[i * 16: (i + 1) * 16]]\n",
    "#    embeddings.extend(oci_embeddings.embed_documents(subdocs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84050aa-5d67-449d-98d7-1ce0b3e0efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store built.\n"
     ]
    }
   ],
   "source": [
    "### Build Vector Store (FAISS)\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "#texts = [item.page_content for item in split_docs]\n",
    "#text_embedding_pairs = [(text, embed) for text, embed in zip(texts, embeddings)]\n",
    "#vectorstore = FAISS.from_embeddings(text_embedding_pairs, oci_embeddings)\n",
    "vectorstore = FAISS.from_documents(split_docs, oci_embeddings)\n",
    "\n",
    "print(\"FAISS vector store built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a178f33e-b6dd-43b6-ada9-0e9865319f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain built.\n"
     ]
    }
   ],
   "source": [
    "### Build Chain (OCI chat-based Retrieval QA)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#rag_prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "#rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.  You don't have to mention whether you did or did not use the context.\n",
    "#{context}\n",
    "#Question: {question}\n",
    "#\"\"\"\n",
    "\n",
    "rag_prompt_template = \"\"\"Try to the question using only the following context, but, if that fails, use your general knowledge.\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "\n",
    "#rag = RetrievalQA.from_chain_type(\n",
    "#    llm=oci_chat,\n",
    "#    retriever=retriever,\n",
    "#    chain_type_kwargs={\"prompt\": rag_prompt,},\n",
    "#)\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=oci_chat,\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "print(\"RAG chain built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13be5fa0-0d0d-4e5a-b9ff-fe12c34bfc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What are the 4 pillars of performance?', 'result': 'The 4 pillars of performance, as mentioned in the provided context, are:\\n\\n1. **Growth**  \\n2. **Productivity**  \\n3. **Health**  \\n4. **Innovation**  \\n\\nThese pillars form the foundation of the \"Evolving 4-Pillar Approach\" to performance criteria.'}\n",
      "{'query': 'Why is Productivity important?', 'result': \"Productivity is important because it measures an individual's contribution to revenue. This metric helps assess how effectively an individual is generating value for the organization. By tracking productivity, companies can identify areas for improvement, optimize resource allocation, and ensure that employees are aligned with organizational goals. It also provides a basis for evaluating performance and making informed decisions about growth and development.\"}\n",
      "{'query': 'Can I ignore any of the 4 pillars of performance?', 'result': 'Based on the provided context, it seems that the 4-Pillar Approach (Growth, Productivity, Health, and Innovation) is presented as a comprehensive framework for performance. However, the context does not explicitly state whether any of these pillars can be ignored. \\n\\nSince there is no information suggesting that any pillar is optional or less important than the others, it would be best to assume that all four pillars are essential components of the performance criteria. Ignoring any one of them might lead to an incomplete or unbalanced approach to performance. \\n\\nIf you need more specific guidance on whether any pillar can be ignored in a particular situation, I would recommend seeking additional information or consulting with someone who has expertise in this area. For now, based on the given context, I cannot confirm that any of the 4 pillars can be ignored.'}\n"
     ]
    }
   ],
   "source": [
    "### Invoke the chain (unit test)\n",
    "print(rag.invoke(\"What are the 4 pillars of performance?\"))\n",
    "print(rag.invoke(\"Why is Productivity important?\"))\n",
    "print(rag.invoke(\"Can I ignore any of the 4 pillars of performance?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0adc8c1e-a5df-4d07-b6a2-f8cdf3dd42c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Available</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Not Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Available     Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Not Available Local tested .predict from score.py                               \n",
       "save()    Not Available Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use ADS to deploy the unit-tested chain\n",
    "## Create the ADS deployment object\n",
    "import tempfile\n",
    "from ads.llm.deploy import ChainDeployment\n",
    "\n",
    "artifact_dir = tempfile.mkdtemp()\n",
    "\n",
    "ads_deployment = ChainDeployment(\n",
    "    chain=rag,\n",
    "    artifact_dir=artifact_dir,\n",
    "    force_overwrite=True\n",
    ")\n",
    "\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b2d73e-63bf-42d1-bc0b-22ce9e3acba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/datascience/conda/python_p312_any_x86_64_v1/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23375/3364479652.py\", line 2, in <module>\n",
      "    ads_deployment.prepare(\n",
      "  File \"/home/datascience/conda/python_p312_any_x86_64_v1/lib/python3.12/site-packages/ads/llm/deploy.py\", line 36, in prepare\n",
      "    f.write(yaml.safe_dump(dump(self.chain)))\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/datascience/conda/python_p312_any_x86_64_v1/lib/python3.12/site-packages/ads/llm/serialize.py\", line 209, in dump\n",
      "    return __save(obj)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/datascience/conda/python_p312_any_x86_64_v1/lib/python3.12/site-packages/ads/llm/serialize.py\", line 184, in __save\n",
      "    obj.save(temp_file.name)\n",
      "  File \"/home/datascience/conda/python_p312_any_x86_64_v1/lib/python3.12/site-packages/langchain_classic/chains/base.py\", line 781, in save\n",
      "    raise NotImplementedError(msg)\n",
      "NotImplementedError: Chain verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOCIGenAI(client=<oci.generative_ai_inference.generative_ai_inference_client.GenerativeAiInferenceClient object at 0x7f75b46a88c0>, model_id='cohere.command-a-03-2025', model_kwargs={'temperature': 0.7, 'max_tokens': 500}, service_endpoint='https://inference.generativeai.us-chicago-1.oci.oraclecloud.com', compartment_id='ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a'), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['FAISS', 'OCIGenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f75afee48f0>, search_kwargs={}) does not support saving.\n",
      "NotImplementedError: Chain verbose=False combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question.\\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatOCIGenAI(client=<oci.generative_ai_inference.generative_ai_inference_client.GenerativeAiInferenceClient object at 0x7f75b46a88c0>, model_id='cohere.command-a-03-2025', model_kwargs={'temperature': 0.7, 'max_tokens': 500}, service_endpoint='https://inference.generativeai.us-chicago-1.oci.oraclecloud.com', compartment_id='ocid1.compartment.oc1..aaaaaaaa52sp42nqmtwwzzvmp5mmldri26razhrbyw7cvixmims7p5crsg7a'), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') retriever=VectorStoreRetriever(tags=['FAISS', 'OCIGenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f75afee48f0>, search_kwargs={}) does not support saving."
     ]
    }
   ],
   "source": [
    "# Prepare the ADS deployment\n",
    "ads_deployment.prepare(\n",
    "    inference_conda_env=\"python_p312_any_x86_64_v1\",\n",
    "    inference_python_version=\"3.12\",\n",
    ")\n",
    "\n",
    "# Summarize the checkpoitn ADS workflow status\n",
    "ads_deployment.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3ee04-cb74-4540-8276-8f260e9b1c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_p312_any_x86_64_v1]",
   "language": "python",
   "name": "conda-env-python_p312_any_x86_64_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
